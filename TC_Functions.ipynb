{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 23 07:17:44 2021\n",
    "\n",
    "@author: ajith.masthand\n",
    "\"\"\"\n",
    "\n",
    "### Test-Control pairing function\n",
    "def tc_pairing():\n",
    "    ### Run Interactively\n",
    "    global int_response\n",
    "    int_response=interactive()\n",
    "    \n",
    "    inp_path=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Pairing - Inputs',index_col='input_parameter')\n",
    "    global inp_par\n",
    "    inp_par=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Pairing - Interactive',index_col='input_parameter')\n",
    "    \n",
    "    tc_input=pd.read_csv(inp_path['value']['input_data_path'])\n",
    "    tc_input['IMS_ID']=tc_input['IMS_ID'].astype(str)\n",
    "    print(\"\\nData imported with below columns\\n\")\n",
    "    print(list(tc_input.columns))\n",
    "    \n",
    "    ### Creating aggregate columns\n",
    "    print(\"\\nAggregate columns will be created for TRX, NRX, PDE, SAM using C3M, P3M, C6M, P6M, 12M\")\n",
    "    \n",
    "    for var in ['TRX','NRX','PDE','SAM']:\n",
    "        tc_input[var+'_C3M']=tc_input.loc[:,var+'_01':var+'_03'].sum(axis=1)\n",
    "        tc_input[var+'_P3M']=tc_input.loc[:,var+'_04':var+'_06'].sum(axis=1)\n",
    "        tc_input[var+'_C6M']=tc_input.loc[:,var+'_01':var+'_06'].sum(axis=1)\n",
    "        tc_input[var+'_P6M']=tc_input.loc[:,var+'_07':var+'_12'].sum(axis=1)\n",
    "        tc_input[var+'_12M']=tc_input.loc[:,var+'_01':var+'_12'].sum(axis=1)\n",
    "    del var\n",
    "    \n",
    "    ### Universe Filter\n",
    "    tc_input=analysis_univ(tc_input)\n",
    "    \n",
    "    ### Deciling\n",
    "    tc_input=ntile(tc_input)\n",
    "    \n",
    "    ### Test Control Split\n",
    "    test_data,control_data=tc_split(tc_input)\n",
    "    \n",
    "    ### Test Control Pairing\n",
    "    \n",
    "    ### Splitting Test data into chunks to have < 10K HCPs per chunk to avoid memory / sizing issues\n",
    "    ### And creating Test Control pairs by processing multiple chunk level pairs\n",
    "    ### The function includes cat_match, tol_limit, normalize and pairing functions\n",
    "    tc_match,tc_pair,tc_dist=chunk_proc(tc_input,test_data,control_data)\n",
    "    \n",
    "    ### Type of pairing to be implemented\n",
    "    ### The function matches the pairs based on One-One or Many-One mapping\n",
    "    tc_pair,tc_dist=pair_type(tc_pair,tc_dist,test_data,control_data)\n",
    "    \n",
    "    ### Optional Iterations for Leftover / Unmapped Test / Control HCPs\n",
    "    \n",
    "    response = 'y'\n",
    "    while (response.lower() == \"y\"):\n",
    "        print(\"\\nDo you wish to map leftover Test / Control HCPs? (Y/N)\")\n",
    "        response = input()\n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nFinal Test Control pairing Summary\\n\")\n",
    "            print(tc_pair['T_IMS_ID'].unique().size,\" Test HCPs are matched with \",\n",
    "                  tc_pair['C_IMS_ID'].unique().size,\" Control HCPs\",\"\\n\")\n",
    "            print(test_data['T_IMS_ID'].unique().size,\" Test HCPs and \",\n",
    "                  control_data['C_IMS_ID'].unique().size,\" Control HCPs were created in Total\")\n",
    "            ### Generating trend charts for Test Control pairs\n",
    "            #Creating Test Data, Control Data with out prefixes T_ or C_\n",
    "            #Creating campaign exposed HCPs same as Test HCPs who are paired\n",
    "            test_data_1=test_data.copy()\n",
    "            control_data_1=control_data.copy()\n",
    "            test_data_1.columns=test_data_1.columns.str[2:]\n",
    "            control_data_1.columns=control_data.columns.str[2:]\n",
    "            camp_hcp=pd.DataFrame(tc_pair.loc[:,'T_IMS_ID'])\n",
    "            cross_master_data,vertical_master_data=lift_master(tc_pair,test_data_1,control_data_1,camp_hcp)\n",
    "            trend_data_dict=pairing_trends(cross_master_data,vertical_master_data)\n",
    "            ### Exporting Final results\n",
    "            output(tc_input,tc_pair,inp_path,trend_data_dict)\n",
    "        elif (response.lower() == \"y\"):\n",
    "            int_response=interactive()\n",
    "            inp_par=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Pairing - Interactive',index_col='input_parameter')\n",
    "            tc_pair,test_data,control_data=remap(tc_pair,tc_input,test_data,control_data)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    \n",
    "    del response\n",
    "    del inp_par,inp_path,int_response\n",
    "    del tc_dist,tc_match\n",
    "    ### Pairing Complete\n",
    "     \n",
    "    return tc_input,tc_pair,test_data,control_data\n",
    "   \n",
    "### TC pairing interactive function\n",
    "def interactive():\n",
    "    print(\"\\nWould you like to run interactively (Y/N)?\")\n",
    "    response=\"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        response=input()\n",
    "        if (response.lower() == \"n\"):\n",
    "            interactive=\"n\"\n",
    "            print(\"\\nThe tool will be run with the inputs provided in 'Input Parametrs.xlsx' file\")\n",
    "            print(\"\\nIs the 'Pairing - Interactive' sheet in the excel file updated with all the parameters (Y/N)\")\n",
    "            update=\"NA\"\n",
    "            while (update.lower() != \"y\"):\n",
    "                update = input()\n",
    "                if (update.lower() == \"n\"):\n",
    "                    print(\"\\nPlease update the sheet and type Y\")\n",
    "                elif (update.lower() == \"y\"):\n",
    "                    print(\"\\nParameters in 'Pairing - Interactive' sheet will be used\")\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type Y or N\")\n",
    "        elif (response.lower() == \"y\"):\n",
    "            interactive=\"y\"\n",
    "            print(\"\\nThe tool will be run intractively\\n\")\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return interactive\n",
    "\n",
    "### TC pairing Analysis Universe\n",
    "def analysis_univ(tc_input):\n",
    "    tc_input=tc_input.copy()\n",
    "    print(\"\\n\",tc_input.shape[0],\" records are present in the data\")\n",
    "    print(\"\\nDo you wish to filter analysis universe based on certain columns in the data? (Y/N)\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_1']\n",
    "            print(response)\n",
    "        \n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nAnalysis Universe is unaltered\")\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(list(tc_input.columns))\n",
    "            print(\"\\nEnter the column name/s on which 0 value records need to be filtered out separated by a comma(,) and a space( )?\")\n",
    "            print(\"\\nEg.: If you enter PDE_12M, NRX_12M records with both PDE_12M as 0 AND NRX_12M as 0 will be filtered out\")\n",
    "            response = \"NA\"\n",
    "            while (np.invert(set(response).issubset(tc_input.columns))):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['columns_1']\n",
    "                    print(response)\n",
    "                \n",
    "                response=response.split(\", \")\n",
    "                if (set(response).issubset(tc_input.columns)):\n",
    "                    tc_input['univ_flag']=tc_input[response].sum(axis=1)\n",
    "                    tc_input=tc_input.loc[tc_input['univ_flag']>0,:].drop(['univ_flag'],axis='columns')\n",
    "                    print(\"\\n\",tc_input.shape[0],\" records are present in the data after filtering\")\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type correct column name/s\")\n",
    "            response=\"y\"\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return tc_input\n",
    "\n",
    "### TC pairing ntiling\n",
    "def ntile(tc_input):\n",
    "    tc_input=tc_input.copy()\n",
    "    print(\"\\nDo you have a column for ntile(Decile, Quintile)? (Y/N)\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_2']\n",
    "            print(response)\n",
    "        \n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nDo you wish to create ntile? (Y/N)\\n\")\n",
    "            response = \"NA\"\n",
    "            while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['y_n_3']\n",
    "                    print(response)\n",
    "                \n",
    "                if (response.lower() == \"n\"):\n",
    "                    print(\"\\nProceeding with out ntiling\")\n",
    "                elif (response.lower() == \"y\"):\n",
    "                    print(list(tc_input.columns))\n",
    "                    print(\"\\nEnter the name of the column on which ntiling has to be performed\")\n",
    "                    response = \"NA\"\n",
    "                    while (sum(tc_input.columns == response) == 0):\n",
    "                        if (int_response==\"y\"):\n",
    "                            response=input()\n",
    "                        else:\n",
    "                            response=inp_par['value']['columns_3']\n",
    "                            print(response)\n",
    "                        \n",
    "                        if (sum(tc_input.columns == response) > 0):\n",
    "                            print(\"\\nEnter value of n for ntiling (10 for deciling, 5 for quintiling etc..)\")\n",
    "                            response1=0\n",
    "                            while (response1 < 1):\n",
    "                                if (int_response==\"y\"):\n",
    "                                    response1=int(input())\n",
    "                                else:\n",
    "                                    response1=int(inp_par['value']['number_3'])\n",
    "                                    print(response1)\n",
    "                                \n",
    "                                if (response1 >= 1):\n",
    "                                    print(\"\\nntiling will be performed on \",response,\" with n = \",response1)\n",
    "                                else:\n",
    "                                    print(\"\\nInvalid Response. Please type an integer value > 1\")\n",
    "                            \n",
    "                            decile_data=tc_input[['IMS_ID',response]]\n",
    "                            decile_data=decile_data.sort_values(response,ascending=False).reset_index(drop=True)\n",
    "                            decile_data['cum_rx']=decile_data[response].cumsum()\n",
    "                            rx_sum=decile_data[response].sum()\n",
    "                            decile_data['decile']=response1-(((decile_data['cum_rx']/(rx_sum+0.9999))*response1).astype(int))\n",
    "                            decile_data.loc[decile_data[response]==0,'decile']=0\n",
    "                            \n",
    "                            ## Dropping 'decile' column from original data if it's present to avoid duplicates\n",
    "                            if (sum(tc_input.columns == 'decile') > 0):\n",
    "                                tc_input=tc_input.drop(['decile'],axis='columns')\n",
    "                            tc_input=pd.merge(tc_input,decile_data[['IMS_ID','decile']],on='IMS_ID',how='left')\n",
    "                            del rx_sum, decile_data, response1\n",
    "                            print(\"\\nntiling complete based on column \",response)\n",
    "                            print(\"\\ndecile column has been created with decile / ntile information\")\n",
    "                        else:\n",
    "                            print(\"\\nInvalid Response. Please type the correct column name\")\n",
    "                    response='y'\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type Y or N\")\n",
    "            response='n'\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(list(tc_input.columns))\n",
    "            print(\"\\nEnter the name of the column which contains ntile\")\n",
    "            response = \"NA\"\n",
    "            while (sum(tc_input.columns == response) == 0):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['columns_2']\n",
    "                    print(response)\n",
    "                \n",
    "                if (sum(tc_input.columns == response) > 0):\n",
    "                    print(\"\\n\",response,\" column will be used for decile\")\n",
    "                    tc_input['decile']=tc_input[response]\n",
    "                    print(\"\\ndecile column has been created with decile / ntile information\")\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type the correct column name\")\n",
    "            response='y'\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return tc_input\n",
    "\n",
    "\n",
    "### TC pairing Test Control Split\n",
    "def tc_split(tc_input):\n",
    "    tc_input=tc_input.copy()\n",
    "    print(\"\\nDo you have a TC_Flag that indicates whether HCP is a Test or Control? (Y/N)\\n\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_4']\n",
    "            print(response)\n",
    "        \n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nTest & Control split will be done using Stratified sampling approach\")\n",
    "            print(\"\\nEnter % of HCPs you want as your Test Universe (Eg: If you want 80% of your universe to be Test HCPs and 20% to be Control HCPs, Enter 80)\\n\")\n",
    "            response = 0\n",
    "            while ((response < 1) | (response > 99)):\n",
    "                if (int_response==\"y\"):\n",
    "                    response = int(input())\n",
    "                else:\n",
    "                    response=int(inp_par['value']['number_4'])\n",
    "                    print(response)\n",
    "                \n",
    "                if (1 <= response <= 99):\n",
    "                    print(list(tc_input.columns))\n",
    "                    print(\"\\nEnter column name/s on which you wish to maintain similar distribution in Test/Control universes separated by a comma(,) and a space( )\")\n",
    "                    response1 = \"NA\"\n",
    "                    while (np.invert(set(response1).issubset(tc_input.columns))):\n",
    "                        if (int_response==\"y\"):\n",
    "                            response1=input()\n",
    "                        else:\n",
    "                            response1=inp_par['value']['columns_4']\n",
    "                            print(response1)\n",
    "                        response1=response1.split(\", \")\n",
    "                        if (set(response1).issubset(tc_input.columns)):\n",
    "                            print(\"\\nStratified Sampling will be performed with \",response,\"% as Test HCPs and maintaining similar distribution of \",response1,\" in Test/Control Universe\")\n",
    "                            test_data, control_data = train_test_split(tc_input, train_size=response/100, \n",
    "                                                                       random_state=45, \n",
    "                                                                       stratify=tc_input[response1])\n",
    "                        else:\n",
    "                            print(\"\\nInvalid Response. Please type the correct column name/s\")\n",
    "                    del response1\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type a value between 1 - 99\")\n",
    "            response='n'\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(list(tc_input.columns))\n",
    "            print(\"\\nEnter the name of the column that indicates whether HCP is a Test or Control? (The column must have T or C as it's distinct values')\")\n",
    "            response=\"NA\"\n",
    "            while (sum(tc_input.columns == response) == 0):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['columns_4']\n",
    "                    print(response)\n",
    "                if (sum(tc_input.columns == response) > 0):\n",
    "                    print(response,\" column will be used as Test Control Flag\")\n",
    "                    test_data=tc_input.loc[tc_input[response].str.upper()=='T',:]\n",
    "                    control_data=tc_input.loc[tc_input[response].str.upper()=='C',:]\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type the correct column name\")\n",
    "            response='y'\n",
    "        else:\n",
    "            print(\"Invalid Response. Please type Y or N\")\n",
    "    print(\"\\nTest & Control data is separated and columns in Test & Control data are prefixed with T_ & C_ respectively\")\n",
    "    test_data.columns=\"T_\"+test_data.columns\n",
    "    control_data.columns=\"C_\"+control_data.columns\n",
    "    return test_data,control_data\n",
    "\n",
    "### TC pairing Matching on Categorical data\n",
    "def cat_match(tc_input,test_data,control_data):\n",
    "    tc_input=tc_input.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    print(\"\\nDo you wish to match Test & Control pairs based on certain categorical data first? (Y/N)\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_5']\n",
    "            print(response)\n",
    "        if (response.lower() == \"n\"):\n",
    "            test_data['tmp']=1\n",
    "            control_data['tmp']=1\n",
    "            tc_match=pd.merge(test_data,control_data,on='tmp',how='inner').drop(['tmp'],axis='columns')\n",
    "            if (tc_match.isnull().sum(axis=1).sum() > 0):\n",
    "                print(\"\\nNull values present in the data are replaced with 0\")\n",
    "                tc_match.fillna(0)\n",
    "            print(\"\\n\",tc_match.T_IMS_ID.unique().size,\" Test HCPs are matched with \",\n",
    "                  tc_match.C_IMS_ID.unique().size,\" Control HCPs\")\n",
    "            print(\"\\nProceeding to Tolerance Matching\")\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(\"\\nDisplaying column names for reference\\n\")\n",
    "            print(list(tc_input.columns))\n",
    "            print(\"\\nEnter name/s of the column/s on which you wish to have an exact match separated by a comma(,) and a space( )\")\n",
    "            response = \"NA\"\n",
    "            while (np.invert(set(response).issubset(tc_input.columns))):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['columns_5']\n",
    "                    print(response)\n",
    "                response=response.split(', ')\n",
    "                if (set(response).issubset(tc_input.columns)):\n",
    "                    tc_match=pd.merge(test_data,control_data,how='inner',\n",
    "                                      left_on=[\"T_\" + x for x in response],\n",
    "                                      right_on=[\"C_\" + x for x in response])\n",
    "                    if (tc_match.isnull().sum(axis=1).sum() > 0):\n",
    "                        print(\"\\nNull values present in the data are replaced with 0\")\n",
    "                        tc_match.fillna(0)\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type correct name/s\")\n",
    "                print(\"\\nBefore matching on Categorical data\")\n",
    "                print(\"\\n\",test_data.T_IMS_ID.unique().size,\" Test HCPs are matched with \",\n",
    "                      control_data.C_IMS_ID.unique().size,\" Control HCPs\")\n",
    "                print(\"\\nAfter matching on Categorical data\")\n",
    "                print(\"\\n\",tc_match.T_IMS_ID.unique().size,\" Test HCPs are matched with \",\n",
    "                      tc_match.C_IMS_ID.unique().size,\" Control HCPs\")\n",
    "            response=\"y\"\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return tc_match\n",
    "\n",
    "### TC pairing Tolerance limit application\n",
    "def tol_limit(tc_input,tc_match):\n",
    "    tc_input=tc_input.copy()\n",
    "    tc_match=tc_match.copy()\n",
    "    print(\"\\nDo you wish to set tolerance limits on certain metrics of Control HCPs? (Y/N)\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_6']\n",
    "            print(response)\n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nProceeding to standardize numerical data\")\n",
    "            break\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(\"\\nDisplaying column names for reference\\n\")\n",
    "            print(list(tc_input.columns))\n",
    "            print(\"\\nEnter name/s of the column/s on which you wish set tolerance limits separated by a comma(,) and a space( )\")\n",
    "            response = \"NA\"\n",
    "            while (np.invert(set(response).issubset(tc_input.columns))):\n",
    "                if (int_response==\"y\"):\n",
    "                    response=input()\n",
    "                else:\n",
    "                    response=inp_par['value']['columns_6']\n",
    "                    print(response)\n",
    "                response=response.split(', ')\n",
    "                if (set(response).issubset(tc_input.columns)):\n",
    "                    print(\"\\nEnter Tolerance limits for each of these metrics in the same order separated by a comma(,) and a space( )\")\n",
    "                    print(\"\\nEnter values between 0 and 1. Eg. 0 is exact match, 0.1 is +/- 10%, 0.7 is +/- 70% etc..\")\n",
    "                    response1=list(range(1,10000))\n",
    "                    while (len(response1)!=len(response)):\n",
    "                        if (int_response==\"y\"):\n",
    "                            response1=str(input())\n",
    "                        else:\n",
    "                            response1=str(inp_par['value']['number_6'])\n",
    "                            print(response1)\n",
    "                        response1=response1.split(\", \")\n",
    "                        response1=[float(x) for x in response1]\n",
    "                        if (len(response1)==len(response)):\n",
    "                            counter=0\n",
    "                            print(\"\\nBefore Tolerance application\")\n",
    "                            print(\"\\n\",tc_match.T_IMS_ID.unique().size,\" Test HCPs are matched with \",\n",
    "                                  tc_match.C_IMS_ID.unique().size,\" Control HCPs\")\n",
    "                            for var in response:\n",
    "                                limit=response1[counter]\n",
    "                                tc_match=tc_match.loc[tc_match['C_'+var].between((1-limit)*tc_match['T_'+var],\n",
    "                                                                                 (1+limit)*tc_match['T_'+var],\n",
    "                                                                                 inclusive=True),:]\n",
    "                                counter=counter+1\n",
    "                            print(\"\\nAfter Tolerance application\")\n",
    "                            print(\"\\n\",tc_match.T_IMS_ID.unique().size,\" Test HCPs are matched with \",\n",
    "                                  tc_match.C_IMS_ID.unique().size,\" Control HCPs\")\n",
    "                            del counter, var, limit\n",
    "                        else:\n",
    "                            print(\"\\nInvalid Response. Please type correct order of values\")\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type correct name/s\")\n",
    "                del response1\n",
    "            response=\"y\"\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return tc_match\n",
    "\n",
    "### TC pairing Data Standardization\n",
    "def normalize(tc_input,tc_match):\n",
    "    tc_input=tc_input.copy()\n",
    "    tc_match=tc_match.copy()\n",
    "    print(\"\\nDisplaying column names for reference\\n\")\n",
    "    print(list(tc_input.columns))\n",
    "    print(\"\\nEnter column name/s on which you wish to calculate distance\")\n",
    "    response = \"NA\"\n",
    "    while (np.invert(set(response).issubset(tc_input.columns))):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['columns_7']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response.append('IMS_ID')\n",
    "        if (set(response).issubset(tc_input.columns)):\n",
    "            response1=pd.concat([pd.Series([\"T_\" + x for x in response]),pd.Series([\"C_\" + x for x in response])])\n",
    "            tc_dist=tc_match[response1]\n",
    "            print(\"\\nChoose type of standardization \\n1 - Z Score Normalization \\n2 - Min Max Normalization \\n3 - No Normalization \\n(Enter 1 / 2 / 3)\")\n",
    "            response2=0\n",
    "            while ((response2 != 1) & (response2 != 2) & (response2 != 3)):\n",
    "                if (int_response==\"y\"):\n",
    "                    response2=int(input())\n",
    "                else:\n",
    "                    response2=int(inp_par['value']['number_7'])\n",
    "                    print(response2)\n",
    "                \n",
    "                if (response2==1):\n",
    "                    for var in tc_dist.columns:\n",
    "                        if ((var != 'T_IMS_ID') & (var != 'C_IMS_ID')):\n",
    "                            tc_dist[var]=(tc_dist[var] - tc_dist[var].mean())/tc_dist[var].std(ddof=0)\n",
    "                    print(\"\\nVariables Normalized with Z-Score Normalization\")\n",
    "                    del var\n",
    "                elif (response2==2):\n",
    "                    for var in tc_dist.columns:\n",
    "                        if ((var != 'T_IMS_ID') & (var != 'C_IMS_ID')):\n",
    "                            mini=tc_dist[var].min()\n",
    "                            maxi=tc_dist[var].max()\n",
    "                            tc_dist[var]=(tc_dist[var] - mini)/(maxi - mini)\n",
    "                            del mini,maxi\n",
    "                    print(\"\\nVariables Normalized with Min-Max Normalization\")\n",
    "                    del var\n",
    "                elif (response2==3):\n",
    "                    print(\"\\nProceeding with out normalization\")\n",
    "                else:\n",
    "                    print (\"\\nInvalid Response. Please type 1 or 2 or 3\")\n",
    "            \n",
    "            del response1,response2\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct name/s\")\n",
    "    return tc_dist\n",
    "\n",
    "### TC pairing Creating pairs\n",
    "def pairing(tc_dist,test_data,control_data):\n",
    "    tc_dist=tc_dist.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    print(\"\\nChoose Algorithm for Test & Control matching \\n1 - Euclidean Distance\\n2 - Propensity Score\\nEnter 1 / 2\")\n",
    "    response=0\n",
    "    while ((response!=1) & (response!=2)):\n",
    "        if (int_response==\"y\"):\n",
    "            response=int(input())\n",
    "        else:\n",
    "            response=int(inp_par['value']['number_8'])\n",
    "            print(response)\n",
    "        \n",
    "        if (response==1):\n",
    "            weights,wt_columns=weightages(tc_dist)\n",
    "            tc_dist['euc_dist']=0\n",
    "            counter=0\n",
    "            for var in (wt_columns):\n",
    "                tc_dist['euc_dist']=tc_dist['euc_dist']+((tc_dist['T_'+var]-tc_dist['C_'+var])**2)*weights[counter]\n",
    "                counter=counter+1\n",
    "            del var\n",
    "            tc_dist=tc_dist.sort_values(['T_IMS_ID','euc_dist'],ascending = True)\n",
    "            tc_pair=tc_dist.drop_duplicates(subset=['T_IMS_ID'],keep='first')\n",
    "            tc_pair=tc_pair[['T_IMS_ID','C_IMS_ID']]\n",
    "            print(\"\\nChunk wise Test Control pairs are created using Euclidean distance method\\n\")\n",
    "            print(\"\\nChunk level mapping summary\\n\")\n",
    "            print(tc_pair['T_IMS_ID'].unique().size,\" Test HCPs are matched with \",\n",
    "                  tc_pair['C_IMS_ID'].unique().size,\" Control HCPs\")\n",
    "            print(test_data['T_IMS_ID'].unique().size,\" Test HCPs and \",\n",
    "                  control_data['C_IMS_ID'].unique().size,\" Control HCPs were present originally\",\"\\n\")\n",
    "        elif (response==2):\n",
    "            print(\"\\nPropensity Score matching algorithm is WIP Please select 1 - Euclidean Distance\")\n",
    "            response=0\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type 1 / 2\")\n",
    "    return tc_pair,tc_dist\n",
    "\n",
    "### Weightages to distance calculation variables\n",
    "def weightages(tc_dist):\n",
    "    tc_dist=tc_dist.copy()\n",
    "    wt_columns=list(tc_dist.columns.str[2:].unique())\n",
    "    wt_columns.remove('IMS_ID')\n",
    "    print(\"\\nDo you wish to use weightages while calculating Euclidean Distance? (Y/N)\")\n",
    "    print(\"If 'N' is selected, equal weightages will be assigned\")\n",
    "    response = \"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['y_n_7']\n",
    "            print(response)\n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"\\nEqual weightages will be used\")\n",
    "            weightage=1/(len(wt_columns))\n",
    "            weights=[weightage for i in range(tc_dist.columns.str[2:].unique().size-1)]\n",
    "            print(weights)\n",
    "        elif (response.lower() == \"y\"):\n",
    "            print(\"\\nEnter weights for the variables selected in the same order as below separated by a comma(,) and a space( )\")\n",
    "            print(\"\\nEnter values between 0 and 1.\")\n",
    "            print(wt_columns)\n",
    "            response1=list(range(1,10000))\n",
    "            while ((len(response1)!=len(wt_columns)) | (sum(response1)<0.999) | (sum(response1)>1.001)):\n",
    "                if (int_response==\"y\"):\n",
    "                    response1=str(input())\n",
    "                else:\n",
    "                    response1=str(inp_par['value']['number_9'])\n",
    "                    print(response1)\n",
    "                response1=response1.split(\", \")\n",
    "                response1=[float(x) for x in response1]\n",
    "                if ((len(response1)==len(wt_columns)) & (sum(response1)>0.999) & (sum(response1)<1.001)):\n",
    "                    weights=response1\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type correct order of values\")\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return weights,wt_columns\n",
    "\n",
    "### TC pairing chunk processing\n",
    "def chunk_proc(tc_input,test_data,control_data):\n",
    "    tc_input=tc_input.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    \n",
    "    number_of_chunks=math.ceil(test_data.shape[0]/5000)\n",
    "    print(\"\\nStarting Split process with chunks: \", str(number_of_chunks))\n",
    "    for id, df_i in  enumerate(np.array_split(test_data, number_of_chunks)):\n",
    "        print(\"\\nPairing chunk number \",id+1)\n",
    "        #### Exact match on Categorical data\n",
    "        tc_match=cat_match(tc_input,df_i,control_data)\n",
    "\n",
    "        #### Tolerance limits on continuous variables for control HCPs\n",
    "        ##### Eliminating pairs by setting tolerance limits on Control metric w.r.t Test metric\n",
    "        ##### Eg. (1 - limit*Test_Metric) <= Control_Metric <= (1 + limit*Test_Metric)\n",
    "        tc_match=tol_limit(tc_input,tc_match)\n",
    "        \n",
    "        #### Standardizing the data using Z-Score Normalization / Min-Max Normalization\n",
    "        tc_dist=normalize(tc_input,tc_match)\n",
    "        \n",
    "        #### Using Euclidean Distance / Propensity score to create pairs\n",
    "        ##### Selecting Control which has rank = 1\n",
    "        locals()['tc_pair'+str(id)],locals()['tc_dist'+str(id)]=pairing(tc_dist,df_i,control_data)\n",
    "        if(id==0):\n",
    "            tc_pair=locals()['tc_pair'+str(id)]\n",
    "            tc_dist=locals()['tc_dist'+str(id)]\n",
    "        else:\n",
    "            tc_pair=pd.concat([tc_pair,locals()['tc_pair'+str(id)]],axis=0,ignore_index=True)\n",
    "            tc_dist=pd.concat([tc_dist,locals()['tc_dist'+str(id)]],axis=0,ignore_index=True)\n",
    "        del locals()['tc_pair'+str(id)],locals()['tc_dist'+str(id)] , df_i,id                       \n",
    "    print(\"\\nPairing completed with Split process\")\n",
    "    return tc_match,tc_pair,tc_dist\n",
    "\n",
    "### TC pairing type of pairing\n",
    "def pair_type(tc_pair,tc_dist,test_data,control_data):\n",
    "    tc_pair=tc_pair.copy()\n",
    "    tc_dist=tc_dist.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    \n",
    "    print(\"\\nChoose one of the below methods for type of Test Control pairs\\n\")\n",
    "    print(\"1a - Many - One: One Test mapped to One Control & One Control can be mapped to many Tests\")\n",
    "    print(\"1b - One - One: One Test mapped to One Control & One Control mapped to one Test\")\n",
    "    print(\"\\nEnter label number of your choice (Eg. 1a)\")\n",
    "    \n",
    "    match_type=\"NA\"\n",
    "    while (np.invert(match_type in ['1a','1b'])):\n",
    "        \n",
    "        if (int_response==\"y\"):\n",
    "            match_type=input()\n",
    "        else:\n",
    "            match_type=inp_par['value']['choice_1']\n",
    "            print(match_type)\n",
    "        if((match_type=='1a') | (match_type=='1b')):\n",
    "            if(match_type=='1b'):\n",
    "                tc_dist['control_count'] = tc_dist['T_IMS_ID'].map(tc_dist['T_IMS_ID'].value_counts())\n",
    "                tc_dist=tc_dist.sort_values(['control_count','euc_dist','T_IMS_ID','C_IMS_ID'],ascending = True).drop(['control_count'],axis='columns')\n",
    "                tc_pair=tc_dist.drop_duplicates(subset=['C_IMS_ID'],keep='first').drop_duplicates(subset=['T_IMS_ID'],keep='first')\n",
    "                tc_pair=tc_pair[['T_IMS_ID','C_IMS_ID']]\n",
    "            \n",
    "            print(\"\\nTest Control pairs are created using Euclidean distance method by collating different chunks\\n\")\n",
    "            print(\"\\nIntermediate mapping summary\\n\")\n",
    "            print(tc_pair['T_IMS_ID'].unique().size,\" Test HCPs are matched with \",\n",
    "                  tc_pair['C_IMS_ID'].unique().size,\" Control HCPs\")\n",
    "            print(test_data['T_IMS_ID'].unique().size,\" Test HCPs and \",\n",
    "                  control_data['C_IMS_ID'].unique().size,\" Control HCPs were present originally\",\"\\n\")\n",
    "        else:\n",
    "            print(\"\\nEnter appropriate label number of your choice (Eg. 1a) \")\n",
    "    return tc_pair,tc_dist\n",
    "\n",
    "\n",
    "\n",
    "### TC pairing Remapping unmapped HCPs\n",
    "\n",
    "def remap(tc_pair,tc_input,test_data,control_data):\n",
    "    tc_pair=tc_pair.copy()\n",
    "    tc_input=tc_input.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    print(\"\\nRemapping Unmapped Test / Control HCPs through below methods\\n\")\n",
    "    print(\"\\nChoose from the below 3 choices if Test & Control universe are originally given separately\\n\")\n",
    "    print(\"1a - Leftover Test HCPs as new Test, Complete Control Universe as new Control\")\n",
    "    print(\"1b - Leftover Test HCPs as new Test, Leftover Control Universe as new control\")\n",
    "    print(\"1c - Leftover Test HCPs as new Test, Matched Control Universe as new control\")\n",
    "    print(\"\\nChoose from the below 3 choices if Test & Control universe are originally created through sampling\\n\")\n",
    "    print(\"2a - Combine Leftover Test & Leftover Control, ReCreate new Test & new Control from this universe\")\n",
    "    print(\"2b - Combine Leftover Test & Leftover Control, ReCreate new Test & new Control from this universe, Add Matched Control Universe to the new controls\")\n",
    "    print(\"2c - Combine Leftover Test & Leftover Control as new Test, Matched Control Universe as new Control\")\n",
    "    print(\"\\nEnter label number of your choice (Eg. 1a)\")\n",
    "    response=\"NA\"\n",
    "    while (np.invert(response in ['1a','1b','1c','2a','2b','2c'])):\n",
    "        response=input()\n",
    "        if (response=='1a'):\n",
    "            new_test_data=test_data.loc[~(test_data['T_IMS_ID'].isin(tc_pair['T_IMS_ID'])),:]\n",
    "            new_control_data=control_data.copy()\n",
    "        elif (response=='1b'):\n",
    "            new_test_data=test_data.loc[~(test_data['T_IMS_ID'].isin(tc_pair['T_IMS_ID'])),:]\n",
    "            new_control_data=control_data.loc[~(control_data['C_IMS_ID'].isin(tc_pair['C_IMS_ID'])),:]\n",
    "        elif (response=='1c'):\n",
    "            new_test_data=test_data.loc[~(test_data['T_IMS_ID'].isin(tc_pair['T_IMS_ID'])),:]\n",
    "            new_control_data=control_data.loc[control_data['C_IMS_ID'].isin(tc_pair['C_IMS_ID']),:]\n",
    "        elif (response=='2a'):\n",
    "            new_tc_input=tc_input.loc[~(tc_input['IMS_ID'].isin(tc_pair['T_IMS_ID'].append(tc_pair['C_IMS_ID']))),:]\n",
    "            new_test_data,new_control_data=tc_split(new_tc_input)\n",
    "        elif (response=='2b'):\n",
    "            new_tc_input=tc_input.loc[~(tc_input['IMS_ID'].isin(tc_pair['T_IMS_ID'].append(tc_pair['C_IMS_ID']))),:]\n",
    "            new_test_data,new_control_data=tc_split(new_tc_input)\n",
    "            new_control_data=new_control_data.append(control_data.loc[control_data['C_IMS_ID'].isin(tc_pair['C_IMS_ID']),:])\n",
    "        elif (response=='2c'):\n",
    "            new_test_data=tc_input.loc[~(tc_input['IMS_ID'].isin(tc_pair['T_IMS_ID'].append(tc_pair['C_IMS_ID']))),:]\n",
    "            new_test_data.columns=\"T_\"+new_test_data.columns\n",
    "            new_control_data=control_data.loc[control_data['C_IMS_ID'].isin(tc_pair['C_IMS_ID']),:]\n",
    "        else:\n",
    "            print(\"Invalid response. Please type label from the list of choices\")\n",
    "    print(\"\\nNew Test & new Control Universe have been created based on selected choice\")\n",
    "    \n",
    "    ### Splitting Test data into chunks to have < 10K HCPs per chunk to avoid memory / sizing issues\n",
    "    ### And creating Test Control pairs by processing multiple chunk level pairs\n",
    "    ### The function includes cat_match, tol_limit, normalize and pairing functions\n",
    "    new_tc_match,new_tc_pair,new_tc_dist=chunk_proc(tc_input,new_test_data,new_control_data)\n",
    "    \n",
    "    ### Type of pairing to be implemented\n",
    "    ### The function matches the pairs based on One-One or Many-One mapping\n",
    "    new_tc_pair,new_tc_dist=pair_type(new_tc_pair,new_tc_dist,new_test_data,new_control_data)\n",
    "    \n",
    "    ### Updating test data & control data by appending matched TC pair Test/Control data with new Test/Control data \n",
    "    mat_test_data=test_data.loc[test_data['T_IMS_ID'].isin(tc_pair['T_IMS_ID']),:]\n",
    "    mat_control_data=control_data.loc[control_data['C_IMS_ID'].isin(tc_pair['C_IMS_ID']),:]\n",
    "    upd_test_data=mat_test_data.append(new_test_data).drop_duplicates()\n",
    "    upd_control_data=mat_control_data.append(new_control_data).drop_duplicates()\n",
    "    \n",
    "    ### Updating Test Control pairs\n",
    "    upd_tc_pair=tc_pair.append(new_tc_pair).drop_duplicates()\n",
    "    print(\"\\nUpdated mapping summary\\n\")\n",
    "    print(upd_tc_pair['T_IMS_ID'].unique().size,\" Test HCPs are matched with \",\n",
    "          upd_tc_pair['C_IMS_ID'].unique().size,\" Control HCPs\")\n",
    "    print(upd_test_data['T_IMS_ID'].unique().size,\" Test HCPs and \",\n",
    "          upd_control_data['C_IMS_ID'].unique().size,\" Control HCPs were given to this iteration\",\"\\n\")\n",
    "    \n",
    "    return upd_tc_pair,upd_test_data,upd_control_data\n",
    "    \n",
    "### Goodness of fit trend charts for Test Control pairs\n",
    "def pairing_trends(cross_master_data,vertical_master_data):\n",
    "    cross_master_data=cross_master_data.copy()\n",
    "    vertical_master_data=vertical_master_data.copy()\n",
    "    \n",
    "    print(\"\\nEnter oldest and latest month numbers to be used for trend charts\")\n",
    "    print(\"Eg. 12 for oldest month number, 01 for latest month number\")\n",
    "    print(\"\\nEnter month number for oldest month\")\n",
    "    if (int_response==\"y\"):\n",
    "        old_month=input()\n",
    "    else:\n",
    "        old_month=inp_par['value']['number_10']\n",
    "        print(old_month)\n",
    "    \n",
    "    print(\"\\nEnter month number for latest month\")\n",
    "    if (int_response==\"y\"):\n",
    "        lat_month=input()\n",
    "    else:\n",
    "        lat_month=inp_par['value']['number_11']\n",
    "        print(lat_month)\n",
    "    \n",
    "    print(\"\\nEnter metrics you wish to compare trends b/w Test & Control separated by a comma(,) and a space( )\")\n",
    "    print(\"Enter prefixes of the columns already present in the data\")\n",
    "    print(\"Eg.: NRX, PDE\")\n",
    "    response = [\"NULLVALUE\"]\n",
    "    while (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) > 0):\n",
    "        if (int_response==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=inp_par['value']['columns_8']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response=[x.upper() for x in response]\n",
    "        if (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) == 0):\n",
    "            trend_data_dict={}\n",
    "            for var in response:\n",
    "                trend_data_1=pd.DataFrame(cross_master_data.loc[:,'T_' + var + '_' + lat_month:'T_' + var + '_' + old_month].mean(axis=0).reset_index())\n",
    "                trend_data_1['index']=trend_data_1['index'].str.replace(\"T_\"+var+\"_\",\"\").astype(int)\n",
    "                trend_data_1.columns=['month',\"T_\"+var]\n",
    "                \n",
    "                trend_data_2=pd.DataFrame(cross_master_data.loc[:,'C_' + var + '_' + lat_month:'C_' + var + '_' + old_month].mean(axis=0).reset_index())\n",
    "                trend_data_2['index']=trend_data_2['index'].str.replace(\"C_\"+var+\"_\",\"\").astype(int)\n",
    "                trend_data_2.columns=['month',\"C_\"+var]\n",
    "                \n",
    "                trend_data=pd.merge(trend_data_1,trend_data_2,on='month',how='outer').sort_values(by='month',ascending=False)\n",
    "                del trend_data_1,trend_data_2\n",
    "                key_name=var+'_trend'\n",
    "                trend_data_dict[key_name] = copy.deepcopy(trend_data)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct prefixes of columns\")\n",
    "    return trend_data_dict\n",
    "\n",
    "### TC pairing Writing Output to Excel file\n",
    "def output(tc_input,tc_pair,inp_path,trend_data_dict):\n",
    "    test_data_out=tc_input.loc[tc_input.IMS_ID.isin(tc_pair['T_IMS_ID'].unique()),:]\n",
    "    control_data_out=tc_input.loc[tc_input.IMS_ID.isin(tc_pair['C_IMS_ID'].unique()),:]\n",
    "    with pd.ExcelWriter(inp_path['value']['output_data_path']) as writer:  \n",
    "        tc_pair.to_excel(writer, sheet_name='TC_Pair',index=False)\n",
    "        test_data_out.to_excel(writer, sheet_name='Test_Data',index=False)\n",
    "        control_data_out.to_excel(writer, sheet_name='Control_Data',index=False)\n",
    "        for key in trend_data_dict:\n",
    "            trend_data_dict[key].to_excel(writer, sheet_name=key,index=False)\n",
    "    \n",
    "    print(\"\\nFinal results exported to \\n\",inp_path['value']['output_data_path'])\n",
    "    print(\"\\nTest & Control pairing complete\")\n",
    "\n",
    "\n",
    "### Run lift calculation in continuation with Test-Control pairing\n",
    "def run_lift(tc_pair,test_data,control_data):\n",
    "    tc_pair=tc_pair.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    test_data.columns=test_data.columns.str[2:]\n",
    "    control_data.columns=control_data.columns.str[2:]\n",
    "    print(\"\\nWould you like to run Lift calculation with the output of Test-Control matching (Y/N)?\")\n",
    "    response=\"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        response=input()\n",
    "        if (response.lower() == \"n\"):\n",
    "            print(\"Thank You!!!\")\n",
    "            lift_out=pd.DataFrame(np.nan,index=[0], columns=['0'])\n",
    "        elif (response.lower() == \"y\"):\n",
    "            lift_calc(tc_pair,test_data,control_data)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    \n",
    "\n",
    "### Lift calculation Function\n",
    "def lift_calc(tc_pair,test_data,control_data):\n",
    "    tc_pair=tc_pair.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    \n",
    "    ### File paths\n",
    "    global lift_path\n",
    "    lift_path=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Lift - Inputs',index_col='input_parameter')\n",
    "    \n",
    "    ### Finalising inputs\n",
    "    tc_pair,test_data,control_data,camp_hcp=lift_input(tc_pair,test_data,control_data)\n",
    "    \n",
    "    ### Run Interactively\n",
    "    global lift_int\n",
    "    lift_int=lift_interactive()\n",
    "    global lift_par\n",
    "    lift_par=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Lift - Interactive',index_col='input_parameter')\n",
    "    \n",
    "    ### Pre Period & post Period\n",
    "    pre_period,post_period=lift_periods(test_data)\n",
    "    \n",
    "    ### Master Data\n",
    "    cross_master_data,vertical_master_data=lift_master(tc_pair,test_data,control_data,camp_hcp)\n",
    "    \n",
    "    ### Impact Calculaion\n",
    "    camp_impact,camp_lift,emmeans,ancova_summary=lift_impact(cross_master_data,pre_period,post_period,vertical_master_data)\n",
    "    \n",
    "    ### Visualization of Lift analysis\n",
    "    trend_data_dict=lift_trends(cross_master_data,vertical_master_data)\n",
    "    \n",
    "    ### Exporting Lift analysis output\n",
    "    lift_output(trend_data_dict,emmeans,ancova_summary)\n",
    "    \n",
    "    print(\"\\nImpact of campaign on \",lift_param,\" is observed to be \",camp_impact,lift_param,\" per month per HCP\")\n",
    "    print(\"With a lift of \",camp_lift*100,\"%\")\n",
    "    print(\"\\nLift calculation analysis complete\")\n",
    "    \n",
    "\n",
    "#### Lift Inputs function\n",
    "def lift_input(tc_pair,test_data,control_data):\n",
    "    if (lift_calc_indep==\"n\"):\n",
    "        tc_pair=tc_pair.copy()\n",
    "        test_data=test_data.copy()\n",
    "        control_data=control_data.copy()\n",
    "        print(\"\\nTest-Control pairs, Test Data, Control Data will be used from output of Test-Control pairing\")\n",
    "        print(\"\\nChoose from below for list of campaign reached hcps (1/2/3)\")\n",
    "        print(\"\\n1 - Consider Test HCPs from Test-Control pairs data as campaign reached HCPs\")\n",
    "        print(\"2 - Consider campaign reached HCPs list from the location given in 'Lift - Inputs' sheet of 'Input Parameters.xlsx' file \")\n",
    "        print(\"3 - Enter location of .csv file which contains campaign reached HCPs list\")\n",
    "        response=\"NA\"\n",
    "        while (np.invert(response in ['1','2','3'])):\n",
    "            response=input()\n",
    "            if (response == \"1\"):\n",
    "                camp_hcp=tc_pair.drop_duplicates(subset='T_IMS_ID').drop(['C_IMS_ID'],axis='columns')\n",
    "            elif (response == \"2\"):\n",
    "                print(\"\\nIs the 'Lift - Inputs' sheet in the excel file updated with the location of campaign reached HCPs (Y/N)\")\n",
    "                update=\"NA\"\n",
    "                while (update.lower() != \"y\"):\n",
    "                    update = input()\n",
    "                    if (update.lower() == \"n\"):\n",
    "                        print(\"\\nPlease update the sheet and type Y\")\n",
    "                    elif (update.lower() == \"y\"):\n",
    "                        print(\"\\nLocations in 'Lift - Inputs' sheet will be used\")\n",
    "                    else:\n",
    "                        print(\"\\nInvalid Response. Please type Y or N\")\n",
    "                lift_path=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Lift - Inputs',index_col='input_parameter')\n",
    "                camp_hcp=pd.read_csv(lift_path['value']['reached_ims_path'])\n",
    "                camp_hcp['T_IMS_ID']=camp_hcp['T_IMS_ID'].astype(str)\n",
    "            elif (response == \"3\"):\n",
    "                print(\"\\nInput Location of csv file\")\n",
    "                loc=input()\n",
    "                camp_hcp=pd.read_csv(loc)\n",
    "                camp_hcp['T_IMS_ID']=camp_hcp['T_IMS_ID'].astype(str)\n",
    "            else:\n",
    "                print(\"\\nInvalid Response. Please type 1 or 2 or 3\")                                     \n",
    "    elif (lift_calc_indep==\"y\"):\n",
    "        print(\"\\nTest-Control pairs, Test Data, Control Data & Campaign reached HCPs data will be considered as per the inputs provided in 'Input Parametrs.xlsx' file\")\n",
    "        print(\"\\nIs the 'Lift - Inputs' sheet in the excel file updated with all the locations (Y/N)\")\n",
    "        update=\"NA\"\n",
    "        while (update.lower() != \"y\"):\n",
    "            update = input()\n",
    "            if (update.lower() == \"n\"):\n",
    "                print(\"\\nPlease update the sheet and type Y\")\n",
    "            elif (update.lower() == \"y\"):\n",
    "                print(\"\\nLocations in 'Lift - Inputs' sheet will be used\")\n",
    "            else:\n",
    "                print(\"\\nInvalid Response. Please type Y or N\")\n",
    "        lift_path=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Lift - Inputs',index_col='input_parameter')\n",
    "        tc_pair=pd.read_csv(lift_path['value']['tc_pair_inp_path'])\n",
    "        test_data=pd.read_csv(lift_path['value']['test_data_path'])\n",
    "        control_data=pd.read_csv(lift_path['value']['control_data_path'])\n",
    "        camp_hcp=pd.read_csv(lift_path['value']['reached_ims_path'])\n",
    "    \n",
    "    print(\"\\nInput Datasets are imported\")\n",
    "    return tc_pair,test_data,control_data,camp_hcp\n",
    "\n",
    "\n",
    "### Lift calculation Interactive function\n",
    "def lift_interactive():\n",
    "    print(\"\\nWould you like to run lift calculation interactively (Y/N)?\")\n",
    "    response=\"NA\"\n",
    "    while ((response.lower() != \"y\") & (response.lower() != \"n\")):\n",
    "        response=input()\n",
    "        if (response.lower() == \"n\"):\n",
    "            interactive=\"n\"\n",
    "            print(\"\\nThe tool will be run with the inputs provided in 'Input Parametrs.xlsx' file\")\n",
    "            print(\"\\nIs the 'Lift - Interactive' sheet in the excel file updated with all the parameters (Y/N)\")\n",
    "            update=\"NA\"\n",
    "            while (update.lower() != \"y\"):\n",
    "                update = input()\n",
    "                if (update.lower() == \"n\"):\n",
    "                    print(\"\\nPlease update the sheet and type Y\")\n",
    "                elif (update.lower() == \"y\"):\n",
    "                    print(\"\\nParameters in 'Lift - Interactive' sheet will be used\")\n",
    "                else:\n",
    "                    print(\"\\nInvalid Response. Please type Y or N\")\n",
    "        elif (response.lower() == \"y\"):\n",
    "            interactive=\"y\"\n",
    "            print(\"\\nThe tool will be run intractively\\n\")\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    return interactive\n",
    "\n",
    "### Lift calculation periods input\n",
    "def lift_periods(test_data):\n",
    "    test_data=test_data.copy()\n",
    "    print(\"\\nWhich metric would you like to calculate lift on (TRX / NRX)?\")\n",
    "    response=\"NA\"\n",
    "    while ((response.lower() != \"trx\") & (response.lower() != \"nrx\")):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['param_1']\n",
    "            print(response)\n",
    "        if ((response.lower() == \"trx\") | (response.lower() == \"nrx\")):\n",
    "            global lift_param\n",
    "            lift_param=response.upper()\n",
    "            print(\"\\nLift calculation parameter will be considered as \",lift_param)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type TRX / NRX\")\n",
    "    \n",
    "    print(\"\\nEnter months to be considered as pre period separated by a comma(,) and a space( )\")\n",
    "    print(\"Eg. 07, 08, 09, 10, 11\")\n",
    "    print(\"Where 01 represents latest month as per data\")\n",
    "    response = \"NA\"\n",
    "    while (np.invert(set(response).issubset(test_data.columns))):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['columns_1']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response=[lift_param + \"_\" + x for x in response]\n",
    "        if (set(response).issubset(test_data.columns)):\n",
    "            pre_period=response.copy()\n",
    "            print(\"\\nColumns to be used as Pre Period\")\n",
    "            print(pre_period)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct month/s\")\n",
    "    print(\"\\nEnter months to be considered as post period separated by a comma(,) and a space( )\")\n",
    "    print(\"Eg. 01, 02, 03, 04, 05\")\n",
    "    print(\"Where 01 represents latest month as per data\")\n",
    "    response = \"NA\"\n",
    "    while (np.invert(set(response).issubset(test_data.columns))):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['columns_2']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response=[lift_param + \"_\" + x for x in response]\n",
    "        if (set(response).issubset(test_data.columns)):\n",
    "            post_period=response.copy()\n",
    "            print(\"\\nColumns to be used as Post Period\")\n",
    "            print(post_period)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct month/s\")\n",
    "    return pre_period,post_period\n",
    "\n",
    "### Lift calculation Master data creation\n",
    "def lift_master(tc_pair,test_data,control_data,camp_hcp):\n",
    "    tc_pair=tc_pair.copy()\n",
    "    test_data=test_data.copy()\n",
    "    control_data=control_data.copy()\n",
    "    camp_hcp=camp_hcp.copy()\n",
    "    \n",
    "    ### For Difference of Differences lift calculation\n",
    "    cross_master_data=tc_pair.loc[(tc_pair.T_IMS_ID.isin(camp_hcp.T_IMS_ID.unique())) &\n",
    "                                 ~(tc_pair.C_IMS_ID.isin(camp_hcp.T_IMS_ID.unique())),:]\n",
    "    test_data.columns=\"T_\"+test_data.columns\n",
    "    control_data.columns=\"C_\"+control_data.columns\n",
    "    \n",
    "    cross_master_data=pd.merge(cross_master_data,test_data,on='T_IMS_ID',how='left')\n",
    "    cross_master_data=pd.merge(cross_master_data,control_data,on='C_IMS_ID',how='left')\n",
    "    \n",
    "    ### For ANCOVA Lift calculation\n",
    "    test_data_univ=cross_master_data.loc[:,cross_master_data.columns.str.startswith('T_')]\n",
    "    test_data_univ.columns=test_data_univ.columns.str[2:]\n",
    "    control_data_univ=cross_master_data.loc[:,cross_master_data.columns.str.startswith('C_')]\n",
    "    control_data_univ.columns=control_data_univ.columns.str[2:]\n",
    "    \n",
    "    test_data_univ['TC_Flag']='T'\n",
    "    control_data_univ['TC_Flag']='C'\n",
    "    vertical_master_data=test_data_univ.append(control_data_univ,ignore_index=True)\n",
    "    \n",
    "    return cross_master_data, vertical_master_data\n",
    "\n",
    "### Lift calculation Impact\n",
    "def lift_impact(cross_master_data,pre_period,post_period,vertical_master_data):\n",
    "    cross_master_data=cross_master_data.copy()\n",
    "    pre_period=pre_period.copy()\n",
    "    post_period=post_period.copy()\n",
    "    vertical_master_data=vertical_master_data.copy()\n",
    "    print(\"\\nChoose a method from below for lift calculation (1/2/3)\\n\")\n",
    "    print(\"1 - Difference of Differences\")\n",
    "    print(\"2 - ANCOVA\")\n",
    "    print(\"3 - Placeholder\")\n",
    "    response=\"NA\"\n",
    "    while (np.invert(response in ['1','2','3'])):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=str(lift_par['value']['param_2'])\n",
    "            print(response)\n",
    "        if (response=='1'):\n",
    "            test_pre=cross_master_data[[\"T_\" + x for x in pre_period]].mean(axis=1).mean()\n",
    "            test_post=cross_master_data[[\"T_\" + x for x in post_period]].mean(axis=1).mean()\n",
    "            control_pre=cross_master_data[[\"C_\" + x for x in pre_period]].mean(axis=1).mean()\n",
    "            control_post=cross_master_data[[\"C_\" + x for x in post_period]].mean(axis=1).mean()\n",
    "            camp_impact=(test_post-test_pre)-(control_post-control_pre)\n",
    "            camp_lift=camp_impact/control_post\n",
    "            print(\"\\nLift calculated through Difference of Differences \")\n",
    "            \n",
    "            ##Dummy variables for ANCOVA output if DOD is chose for calculating Lift\n",
    "            emmeans=pd.DataFrame(np.nan,index=[0], columns=['0'])\n",
    "            ancova_summary=pd.DataFrame(np.nan,index=[0], columns=['0'])\n",
    "        elif (response=='2'):\n",
    "            camp_impact,camp_lift,emmeans,ancova_summary=ancova_impact(pre_period,post_period,vertical_master_data,cross_master_data)\n",
    "            print(\"\\nLift calculated through ANCOVA\")\n",
    "        elif (response=='3'):\n",
    "            # print(\"\\nLift calculated through method-3\")\n",
    "            print(\"\\nThis method is WIP please select 1\")\n",
    "            response=\"NA\"\n",
    "        else:\n",
    "            print(\"\\nInvalid Response\")\n",
    "    print(\"\\nImpact of campaign on \",lift_param,\" is observed to be \",camp_impact,lift_param,\" per month per HCP\")\n",
    "    print(\"\\nWith a lift of \",camp_lift*100,\"%\")\n",
    "    return camp_impact,camp_lift,emmeans,ancova_summary\n",
    "\n",
    "### Lift calculation through ANCOVA\n",
    "def ancova_impact(pre_period,post_period,vertical_master_data,cross_master_data):\n",
    "    pre_period=pre_period.copy()\n",
    "    post_period=post_period.copy()\n",
    "    vertical_master_data=vertical_master_data.copy()\n",
    "    cross_master_data=cross_master_data.copy()\n",
    "    \n",
    "    ### 1-0 flag for Test & Control\n",
    "    vertical_master_data['TC_Flag']=np.where(vertical_master_data['TC_Flag']=='T',1,0)\n",
    "    ### Variables input for creating Pre Period and Post period metrics\n",
    "    print(\"\\nEnter metrics you wish to create pre and post variables separated by a comma(,) and a space( )\")\n",
    "    print(\"Enter prefixes of the columns already present in the data\")\n",
    "    print(\"Make sure you include lift calculation paramter (Eg. NRX)\")\n",
    "    print(\"Eg.: NRX, PDE\")\n",
    "    response = [\"NULLVALUE\"]\n",
    "    while (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) > 0):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['columns_4']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response=[x.upper() for x in response]\n",
    "        if (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) == 0):\n",
    "            pre_post_var=response\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct prefixes of columns\")\n",
    "    del response\n",
    "    ### Creating Pre & Post period variables\n",
    "    for var in pre_post_var:\n",
    "        vertical_master_data[var+'_PRE']=vertical_master_data[[x.replace(lift_param,var) for x in pre_period]].mean(axis=1)\n",
    "        vertical_master_data[var+'_POST']=vertical_master_data[[x.replace(lift_param,var) for x in post_period]].mean(axis=1)\n",
    "        \n",
    "        cross_master_data['T_'+var+'_PRE']=cross_master_data[['T_'+x.replace(lift_param,var) for x in pre_period]].mean(axis=1)\n",
    "        cross_master_data['T_'+var+'_POST']=cross_master_data[['T_'+x.replace(lift_param,var) for x in post_period]].mean(axis=1)\n",
    "        cross_master_data['C_'+var+'_PRE']=cross_master_data[['C_'+x.replace(lift_param,var) for x in pre_period]].mean(axis=1)\n",
    "        cross_master_data['C_'+var+'_POST']=cross_master_data[['C_'+x.replace(lift_param,var) for x in post_period]].mean(axis=1)\n",
    "        \n",
    "        \n",
    "    del pre_post_var\n",
    "    ### Dependent variable as post lift parmater\n",
    "    vertical_master_data['dep_var']=vertical_master_data[lift_param+'_POST']\n",
    "    print(\"\\nDependent variable is considered as \",lift_param+\"_POST\")\n",
    "    print(\"\\nDisplaying column names for reference\\n\")\n",
    "    print(list(vertical_master_data.columns))\n",
    "    print(\"\\nEnter columns to be considered as independent variables separated by a comma(,) and a space( )\")\n",
    "    print(\"Eg. NRX_PRE, PDE_POST, SAM_POST\")\n",
    "    print(\"TC_Flag is included by default\\n\")\n",
    "    response = \"NA\"\n",
    "    while (np.invert(set(response).issubset(vertical_master_data.columns))):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['columns_5']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        \n",
    "        if (set(response).issubset(vertical_master_data.columns)):\n",
    "            response.append('TC_Flag')\n",
    "            print(\"\\nColumns to be used as independent variables\")\n",
    "            print(response)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct columns\")\n",
    "    indep_var=response\n",
    "    del response\n",
    "    ### OLS regression model\n",
    "    \n",
    "    # defining the variables\n",
    "    x = vertical_master_data[indep_var]\n",
    "    y = vertical_master_data['dep_var']\n",
    "     \n",
    "    # adding the constant term\n",
    "    x = sm.add_constant(x)\n",
    "     \n",
    "    # performing the regression\n",
    "    # and fitting the model\n",
    "    result = sm.OLS(y, x).fit()\n",
    "     \n",
    "    # collating results\n",
    "    ancova_summary=pd.DataFrame(result.params).reset_index()\n",
    "    ancova_summary.columns=['variable','coefficient']\n",
    "    ancova_pvalue=pd.DataFrame(result.pvalues).reset_index()\n",
    "    ancova_pvalue.columns=['variable','pvalue']\n",
    "    ancova_summary=pd.merge(ancova_summary,ancova_pvalue,on='variable',how='left')\n",
    "    del x,y,result,ancova_pvalue\n",
    "    \n",
    "    ## Pre period Lift parameter\n",
    "    print(\"\\n Choose from one of the below choices for pre period lift parameter\\n\")\n",
    "    print(\"a - Average of pre period lift paramter - Control (Single fixed value)\")\n",
    "    print(\"b - Average of pre period lift paramter - Test (Single fixed value)\")\n",
    "    print(\"c - Average of pre period lift paramter - Test & Control (Single fixed value)\")\n",
    "    print(\"d - Actual pre period lift paramter of HCPs (different for different HCPs)\")\n",
    "    # print(\"e - Specific column in the data\")\n",
    "    # print(\"f - Use as per model prediction (Coefficient x pre period lift parameter)\")\n",
    "    print(\"\\nEnter label number of your choice (Eg. a)\")\n",
    "    response=\"NA\"\n",
    "    while (np.invert(response in ['a','b','c','d','e','f'])):\n",
    "        response=input()\n",
    "        if (response=='a'):\n",
    "            vertical_master_data['pre_lift_par']=cross_master_data['C_'+lift_param+'_PRE'].mean()\n",
    "        elif (response=='b'):\n",
    "            vertical_master_data['pre_lift_par']=cross_master_data['T_'+lift_param+'_PRE'].mean()\n",
    "        elif (response=='c'):\n",
    "            vertical_master_data['pre_lift_par']=(cross_master_data['T_'+lift_param+'_PRE'].mean() + \n",
    "                                                         cross_master_data['C_'+lift_param+'_PRE'].mean())/2\n",
    "        elif (response=='d'):\n",
    "            vertical_master_data['pre_lift_par']=vertical_master_data[lift_param+'_PRE']\n",
    "        else:\n",
    "            print(\"Invalid response. Please type label from the list of choices\")\n",
    "    print(\"\\nMetric for Pre period lift parameter impact calculation has been created based on selected choice\")\n",
    "    \n",
    "    # ### Getting count of Test HCPs per control\n",
    "    # ## Poulating count as 1 for Test HCPs\n",
    "    # control_count=cross_master_data.groupby('C_IMS_ID').agg(control_count=('T_IMS_ID','count')).reset_index().rename({'C_IMS_ID':'IMS_ID'},axis='columns')\n",
    "    # vertical_master_data=pd.merge(vertical_master_data,control_count,on='IMS_ID',how='left')\n",
    "    # vertical_master_data['control_count']=vertical_master_data['control_count'].fillna(1)\n",
    "    # del control_count\n",
    "    \n",
    "    ### Impact calculation\n",
    "    vertical_master_data['predicted_impact']=0\n",
    "    for var in ancova_summary['variable']:\n",
    "        coeff=ancova_summary.loc[ancova_summary['variable']==var,'coefficient'].reset_index(drop=True)[0]\n",
    "        if var=='const':\n",
    "            vertical_master_data['predicted_impact']=vertical_master_data['predicted_impact']+coeff*1\n",
    "            vertical_master_data[var+'_impact']=coeff*1\n",
    "        elif var==lift_param+'_PRE':\n",
    "            vertical_master_data['predicted_impact']=vertical_master_data['predicted_impact']+coeff*vertical_master_data['pre_lift_par']\n",
    "            vertical_master_data[var+'_impact']=coeff*vertical_master_data['pre_lift_par']\n",
    "        else:\n",
    "            vertical_master_data['predicted_impact']=vertical_master_data['predicted_impact']+coeff*vertical_master_data[var]\n",
    "            vertical_master_data[var+'_impact']=coeff*vertical_master_data[var]\n",
    "        print(var)\n",
    "        \n",
    "    ## Marginal means of Test & Control\n",
    "    emmeans=vertical_master_data[pd.concat([pd.Series(['TC_Flag','predicted_impact']),\n",
    "                                            pd.Series([x+'_impact' for x in ancova_summary['variable']])])].groupby('TC_Flag').mean().reset_index()\n",
    "    # emmeans['predicted_impact']=emmeans['predicted_impact']/vertical_master_data['TC_Flag'].sum()\n",
    "    # for x in ancova_summary['variable']:\n",
    "    #     emmeans[x+'_impact']=emmeans[x+'_impact']/vertical_master_data['TC_Flag'].sum()\n",
    "    test_impact=emmeans.loc[emmeans['TC_Flag']==1,'predicted_impact'].reset_index(drop=True)[0]\n",
    "    control_impact=emmeans.loc[emmeans['TC_Flag']==0,'predicted_impact'].reset_index(drop=True)[0]\n",
    "    camp_impact=(test_impact-control_impact)\n",
    "    camp_lift=camp_impact/control_impact\n",
    "    camp_pvalue=ancova_summary.loc[ancova_summary['variable']=='TC_Flag','pvalue'].reset_index(drop=True)[0]\n",
    "    print(\"\\nANCOVA modelling complete with pvalue of Campaign observed to be \",camp_pvalue)\n",
    "    return camp_impact,camp_lift,emmeans,ancova_summary\n",
    "\n",
    "\n",
    "### Lift calculation Visualization export\n",
    "def lift_trends(cross_master_data,vertical_master_data):\n",
    "    cross_master_data=cross_master_data.copy()\n",
    "    vertical_master_data=vertical_master_data.copy()\n",
    "    \n",
    "    print(\"\\nEnter oldest and latest month numbers to be used for trend charts\")\n",
    "    print(\"Eg. 12 for oldest month number, 01 for latest month number\")\n",
    "    print(\"\\nEnter month number for oldest month\")\n",
    "    if (lift_int==\"y\"):\n",
    "        old_month=input()\n",
    "    else:\n",
    "        old_month=lift_par['value']['param_3']\n",
    "        print(old_month)\n",
    "    \n",
    "    print(\"\\nEnter month number for latest month\")\n",
    "    if (lift_int==\"y\"):\n",
    "        lat_month=input()\n",
    "    else:\n",
    "        lat_month=lift_par['value']['param_4']\n",
    "        print(lat_month)\n",
    "    \n",
    "    print(\"\\nEnter metrics you wish to compare trends b/w Test & Control separated by a comma(,) and a space( )\")\n",
    "    print(\"Enter prefixes of the columns already present in the data\")\n",
    "    print(\"Eg.: NRX, PDE\")\n",
    "    response = [\"NULLVALUE\"]\n",
    "    while (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) > 0):\n",
    "        if (lift_int==\"y\"):\n",
    "            response=input()\n",
    "        else:\n",
    "            response=lift_par['value']['columns_3']\n",
    "            print(response)\n",
    "        response=response.split(', ')\n",
    "        response=[x.upper() for x in response]\n",
    "        if (sum(~pd.Series([sum(vertical_master_data.columns.str.startswith(x))>0 for x in response])) == 0):\n",
    "            trend_data_dict={}\n",
    "            for var in response:\n",
    "                trend_data_1=pd.DataFrame(cross_master_data.loc[:,'T_' + var + '_' + lat_month:'T_' + var + '_' + old_month].mean(axis=0).reset_index())\n",
    "                trend_data_1['index']=trend_data_1['index'].str.replace(\"T_\"+var+\"_\",\"\").astype(int)\n",
    "                trend_data_1.columns=['month',\"T_\"+var]\n",
    "                \n",
    "                trend_data_2=pd.DataFrame(cross_master_data.loc[:,'C_' + var + '_' + lat_month:'C_' + var + '_' + old_month].mean(axis=0).reset_index())\n",
    "                trend_data_2['index']=trend_data_2['index'].str.replace(\"C_\"+var+\"_\",\"\").astype(int)\n",
    "                trend_data_2.columns=['month',\"C_\"+var]\n",
    "                \n",
    "                trend_data=pd.merge(trend_data_1,trend_data_2,on='month',how='outer').sort_values(by='month',ascending=False)\n",
    "                del trend_data_1,trend_data_2\n",
    "                key_name=var+'_trend'\n",
    "                trend_data_dict[key_name] = copy.deepcopy(trend_data)\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type correct prefixes of columns\")\n",
    "    return trend_data_dict\n",
    "  \n",
    "### Exporting Lift analysis data\n",
    "def lift_output(trend_data_dict,emmeans,ancova_summary):\n",
    "    trend_data_dict=trend_data_dict.copy()\n",
    "    emmeans=emmeans.copy()\n",
    "    ancova_summary=ancova_summary.copy()\n",
    "    print(\"\\nOutput file location will be considered as per the input provided in 'Input Parametrs.xlsx' file\")\n",
    "    print(\"\\nIs the 'Lift - Inputs' sheet in the excel file updated with the output location (Y/N)\")\n",
    "    update=\"NA\"\n",
    "    while (update.lower() != \"y\"):\n",
    "        update = input()\n",
    "        if (update.lower() == \"n\"):\n",
    "            print(\"\\nPlease update the location and type Y\")\n",
    "        elif (update.lower() == \"y\"):\n",
    "            print(\"\\nOutput locations in 'Lift - Inputs' sheet will be used\")\n",
    "        else:\n",
    "            print(\"\\nInvalid Response. Please type Y or N\")\n",
    "    lift_path=pd.read_excel(\"Input/Input Parameters.xlsx\",sheet_name='Lift - Inputs',index_col='input_parameter')\n",
    "    with pd.ExcelWriter(lift_path['value']['output_data_path']) as writer: \n",
    "        for key in trend_data_dict:\n",
    "            trend_data_dict[key].to_excel(writer, sheet_name=key,index=False)\n",
    "        emmeans.to_excel(writer, sheet_name='emmeans_ANCOVA',index=False)\n",
    "        ancova_summary.to_excel(writer, sheet_name='summary_ANCOVA',index=False)\n",
    "        \n",
    "    print(\"\\nLift analysis trends are exported to \\n\",lift_path['value']['output_data_path'])\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
